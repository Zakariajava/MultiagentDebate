"""
Agentes investigadores especializados para el sistema de debates.

Este m√≥dulo implementa los agentes investigadores especializados (SlaveAgents) que
forman parte de los equipos de debate. Cada agente tiene un rol especializado
(cient√≠fico, econ√≥mico, hist√≥rico, etc.) y trabaja para un equipo (PRO o CONTRA),
buscando informaci√≥n relevante desde su perspectiva espec√≠fica.

El sistema incluye mecanismos para buscar informaci√≥n en internet, evaluar su
relevancia, credibilidad y sesgo, y seleccionar los mejores fragmentos para
respaldar los argumentos del equipo.

VERSI√ìN CORREGIDA con rate limiting y campos faltantes
"""
import logging
import time
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass
from enum import Enum

# Imports de tu proyecto
from ..config import AgentRole, Config
from ..utils.search import SearchSystem, SearchResult, SearchError
from ..utils.github_models import get_agent_model

logger = logging.getLogger(__name__)

@dataclass
class Fragment:
    """
    Fragmento de informaci√≥n evaluado por un agente investigador.
    
    Representa una pieza de informaci√≥n encontrada durante la investigaci√≥n,
    evaluada seg√∫n m√∫ltiples criterios (relevancia, credibilidad, sesgo).
    Incluye metadatos como la fuente, URL, puntajes de evaluaci√≥n y
    razonamiento del agente.
    
    Attributes:
        content (str): Contenido textual del fragmento.
        title (str): T√≠tulo del documento o art√≠culo.
        url (str): URL de la fuente.
        source (str): Nombre de la fuente (sitio web, peri√≥dico, etc.).
        relevance_score (float): Puntuaci√≥n de relevancia (0-1).
        credibility_score (float): Puntuaci√≥n de credibilidad de la fuente (0-1).
        bias_score (float): Nivel de sesgo (0=neutral, 1=muy sesgado).
        final_score (float): Puntuaci√≥n final combinada.
        agent_reasoning (str): Justificaci√≥n del agente para seleccionar este fragmento.
        search_query (str): Consulta que gener√≥ este resultado.
        timestamp (datetime): Momento en que se encontr√≥ el fragmento.
        supervisor_team (str): Equipo del supervisor (PRO/CONTRA).
        supervisor_position (str): Posici√≥n que defiende el equipo.
    """
    content: str
    title: str
    url: str
    source: str
    relevance_score: float  # 0-1: qu√© tan relevante es para el tema
    credibility_score: float  # 0-1: qu√© tan cre√≠ble es la fuente
    bias_score: float  # 0-1: qu√© tan sesgado est√° (0=neutral, 1=muy sesgado)
    final_score: float  # Score final combinado
    agent_reasoning: str  # Por qu√© el agente eligi√≥ este fragmento
    search_query: str  # Query que encontr√≥ este fragmento
    timestamp: datetime
    
    # Campos para referencia al supervisor
    supervisor_team: str = ""
    supervisor_position: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        """
        Convierte el fragmento a un diccionario serializable.
        
        √ötil para almacenamiento, transmisi√≥n o visualizaci√≥n de datos.
        
        Returns:
            Dict[str, Any]: Representaci√≥n del fragmento como diccionario.
        """
        return {
            "content": self.content,
            "title": self.title,
            "url": self.url,
            "source": self.source,
            "relevance_score": self.relevance_score,
            "credibility_score": self.credibility_score,
            "bias_score": self.bias_score,
            "final_score": self.final_score,
            "agent_reasoning": self.agent_reasoning,
            "search_query": self.search_query,
            "timestamp": self.timestamp.isoformat(),
            "supervisor_team": self.supervisor_team,
            "supervisor_position": self.supervisor_position
        }

class SlaveAgent:
    """
    Agente investigador especializado para el sistema de debates.
    
    Cada agente tiene una especialidad (cient√≠fico, econ√≥mico, hist√≥rico, etc.)
    y pertenece a un equipo (PRO o CONTRA). Su trabajo principal es buscar
    informaci√≥n relevante desde su perspectiva especializada, evaluarla seg√∫n
    criterios de calidad, y proporcionar los mejores fragmentos para respaldar
    los argumentos del equipo.
    
    El agente implementa todo el ciclo de investigaci√≥n:
    1. Generaci√≥n de consultas especializadas
    2. B√∫squeda de informaci√≥n
    3. Evaluaci√≥n de resultados
    4. Selecci√≥n de los mejores fragmentos
    
    CORRECCIONES:
    - Rate limiting con pausas entre b√∫squedas
    - Mejor manejo de timeouts
    - Validaci√≥n mejorada de argumentos
    """
    
    def __init__(self, role: AgentRole, team: str, agent_id: str = None):
        """
        Inicializa un nuevo agente investigador especializado.
        
        Configura el agente con su rol espec√≠fico, equipo, sistemas de b√∫squeda
        y modelo de lenguaje, adem√°s de inicializar su estado interno.
        
        Args:
            role (AgentRole): Rol especializado del agente (cient√≠fico, econ√≥mico, etc.).
            team (str): Equipo al que pertenece ("pro" o "contra").
            agent_id (str, optional): Identificador √∫nico del agente. Si no se proporciona,
                se genera autom√°ticamente a partir del rol y equipo.
        """
        self.role = role
        self.team = team.lower()
        self.agent_id = agent_id or f"{team}_{role.value}"
        
        # Sistemas externos
        self.search_system = SearchSystem()
        self.llm = get_agent_model(temperature=0.3)  # Temperatura baja para consistencia
        
        # Estado interno
        self.fragments_found = []  # Fragmentos encontrados en la investigaci√≥n
        self.queries_used = []     # Consultas utilizadas previamente
        self.search_history = []   # Historial de b√∫squedas realizadas
        
        # Configuraci√≥n de especialidad seg√∫n el rol
        self.specialty_config = self._configure_specialty()
        
        # Contadores para rate limiting
        self.api_calls_count = 0  # N√∫mero total de llamadas a APIs
        self.last_api_call = None # Timestamp de la √∫ltima llamada a API
        
        logger.info(f"ü§ñ Agente {self.agent_id} ({self.role.value}) inicializado para equipo {self.team}")
    
    def _configure_specialty(self) -> Dict[str, Any]:
        """
        Configura la especializaci√≥n del agente seg√∫n su rol.
        
        Define los tipos de b√∫squeda, palabras clave, fuentes preferidas,
        indicadores de sesgo y plantillas de consulta espec√≠ficas para cada
        especialidad.
        
        Returns:
            Dict[str, Any]: Configuraci√≥n completa de la especialidad.
        """
        specialties = {
            AgentRole.CIENTIFICO: {
                "search_types": ["academic", "general"],
                "keywords": ["estudio", "investigaci√≥n", "cient√≠fico", "evidencia", "datos", "an√°lisis"],
                "preferred_sources": ["pubmed", "scholar", "universidad", "instituto", "journal"],
                "bias_indicators": ["promoci√≥n", "marketing", "opini√≥n personal", "blog personal"],
                "query_templates": [
                    "estudios cient√≠ficos {topic}",
                    "investigaci√≥n m√©dica {topic}",
                    "evidencia cient√≠fica {topic}",
                    "datos cl√≠nicos {topic}",
                    "metaan√°lisis {topic}"
                ]
            },
            AgentRole.ECONOMICO: {
                "search_types": ["economic", "general"],
                "keywords": ["econ√≥mico", "financiero", "costo", "beneficio", "impacto", "mercado"],
                "preferred_sources": ["banco", "ministerio", "estad√≠stica", "econ√≥mico", "financiero"],
                "bias_indicators": ["promoci√≥n comercial", "publicidad", "venta"],
                "query_templates": [
                    "impacto econ√≥mico {topic}",
                    "an√°lisis financiero {topic}",
                    "costos beneficios {topic}",
                    "mercado {topic}",
                    "estad√≠sticas econ√≥micas {topic}"
                ]
            },
            AgentRole.HISTORICO: {
                "search_types": ["general"],
                "keywords": ["hist√≥rico", "historia", "antecedentes", "origen", "evoluci√≥n", "pasado"],
                "preferred_sources": ["museo", "archivo", "historia", "acad√©mico", "universidad"],
                "bias_indicators": ["revisi√≥n hist√≥rica", "interpretaci√≥n moderna"],
                "query_templates": [
                    "historia {topic}",
                    "antecedentes hist√≥ricos {topic}",
                    "evoluci√≥n {topic}",
                    "origen {topic}",
                    "contexto hist√≥rico {topic}"
                ]
            },
            AgentRole.REFUTADOR: {
                "search_types": ["general"],
                "keywords": ["cr√≠tica", "problema", "limitaci√≥n", "contraargumento", "debilidad"],
                "preferred_sources": ["cr√≠tica", "an√°lisis", "revisi√≥n", "oposici√≥n"],
                "bias_indicators": ["defensa absoluta", "sin cr√≠ticas"],
                "query_templates": [
                    "cr√≠ticas {topic}",
                    "problemas {topic}",
                    "limitaciones {topic}",
                    "contraargumentos {topic}",
                    "desventajas {topic}"
                ]
            },
            AgentRole.PSICOLOGICO: {
                "search_types": ["general"],
                "keywords": ["psicol√≥gico", "mental", "emocional", "comportamiento", "social", "cognitivo"],
                "preferred_sources": ["psicolog√≠a", "mental", "comportamiento", "social"],
                "bias_indicators": ["autoayuda", "coaching", "opini√≥n personal"],
                "query_templates": [
                    "efectos psicol√≥gicos {topic}",
                    "impacto mental {topic}",
                    "comportamiento {topic}",
                    "aspectos sociales {topic}",
                    "efectos cognitivos {topic}"
                ]
            }
        }
        
        return specialties.get(self.role, specialties[AgentRole.CIENTIFICO])
    
    def _wait_for_rate_limit(self):
        """
        Implementa el manejo inteligente de rate limiting para llamadas a APIs.
        
        Introduce pausas din√°micas entre llamadas a APIs para evitar alcanzar
        l√≠mites de frecuencia, con base en el tiempo transcurrido desde la √∫ltima
        llamada y un intervalo m√≠nimo configurado.
        """
        current_time = time.time()
        
        if self.last_api_call:
            time_since_last = current_time - self.last_api_call
            min_delay = 1.5  # M√≠nimo 1.5 segundos entre llamadas
            
            if time_since_last < min_delay:
                wait_time = min_delay - time_since_last
                logger.info(f"‚è≥ {self.agent_id} esperando {wait_time:.1f}s para rate limiting...")
                time.sleep(wait_time)
        
        self.last_api_call = time.time()
        self.api_calls_count += 1
    
    def generate_search_queries(self, task: str, context: str = "") -> List[str]:
        """
        Genera consultas de b√∫squeda especializadas seg√∫n el rol del agente.
        
        Utiliza el modelo de lenguaje para crear consultas adaptadas a la
        especialidad del agente, enfocadas en encontrar informaci√≥n relevante
        para su equipo y evitando la duplicaci√≥n con b√∫squedas previas.
        
        Args:
            task (str): Tarea principal de investigaci√≥n.
            context (str, optional): Contexto adicional del debate.
            
        Returns:
            List[str]: Lista de consultas de b√∫squeda especializadas.
        """
        # Esperar para rate limiting antes de llamar al LLM
        self._wait_for_rate_limit()
        
        # Prompt para el LLM que genera las queries
        prompt = f"""
Eres un agente investigador especializado en {self.role.value} del equipo {self.team}.

TAREA: {task}
CONTEXTO: {context}

Tu especialidad se enfoca en: {', '.join(self.specialty_config['keywords'])}

Genera {Config.MAX_QUERIES_PER_AGENT} queries de b√∫squeda espec√≠ficas que:
1. Se enfoquen en tu especialidad ({self.role.value})
2. Busquen evidencia para el equipo {self.team}
3. Sean espec√≠ficas y t√©cnicas
4. Usen t√©rminos relevantes a tu campo
5. Eviten duplicados con queries anteriores

QUERIES ANTERIORES (no repetir):
{self.queries_used[-10:]}  # √öltimas 10 queries para evitar repetir

Formato de respuesta:
1. query espec√≠fica aqu√≠
2. otra query espec√≠fica aqu√≠
3. etc.

Solo responde con las queries numeradas, sin explicaciones adicionales.
"""
        
        try:
            response = self.llm.invoke(prompt)
            queries = []
            
            # Procesar respuesta para extraer las consultas
            for line in response.content.strip().split('\n'):
                if line.strip() and any(char.isdigit() for char in line[:3]):
                    query = line.split('.', 1)[1].strip() if '.' in line else line.strip()
                    if query and len(query) > 10:  # Filtrar queries muy cortas
                        queries.append(query)
            
            # Fallback si el LLM no gener√≥ queries v√°lidas
            if not queries:
                queries = self._generate_fallback_queries(task)
            
            # Guardar queries usadas
            self.queries_used.extend(queries)
            
            logger.info(f"üîç Agente {self.agent_id} gener√≥ {len(queries)} queries")
            return queries[:Config.MAX_QUERIES_PER_AGENT]
            
        except Exception as e:
            logger.error(f"‚ùå Error generando queries para {self.agent_id}: {e}")
            return self._generate_fallback_queries(task)
    
    def _generate_fallback_queries(self, task: str) -> List[str]:
        """
        Genera consultas de respaldo usando plantillas predefinidas.
        
        Utiliza plantillas espec√≠ficas del rol para crear consultas de b√∫squeda
        cuando el modelo de lenguaje falla en generarlas.
        
        Args:
            task (str): Tarea de investigaci√≥n.
            
        Returns:
            List[str]: Lista de consultas de b√∫squeda generadas a partir de plantillas.
        """
        topic = task.lower()
        queries = []
        
        for template in self.specialty_config["query_templates"]:
            query = template.format(topic=topic)
            queries.append(query)
        
        return queries[:Config.MAX_QUERIES_PER_AGENT]
    
    def search_and_evaluate(self, queries: List[str]) -> List[Fragment]:
        """
        Realiza b√∫squedas y eval√∫a cada resultado para convertirlo en fragmentos.
        
        Ejecuta las consultas de b√∫squeda, procesa los resultados obtenidos,
        eval√∫a su calidad mediante el modelo de lenguaje, y selecciona los
        mejores fragmentos, implementando pausas entre operaciones para evitar
        rate limiting.
        
        Args:
            queries (List[str]): Lista de consultas de b√∫squeda a ejecutar.
            
        Returns:
            List[Fragment]: Lista de fragmentos evaluados y filtrados por calidad.
        """
        all_fragments = []
        
        for i, query in enumerate(queries):
            try:
                logger.info(f"üîç {self.agent_id} buscando: '{query}'")
                
                # Pausa entre b√∫squedas (excepto la primera) para evitar rate limiting
                if i > 0:
                    pause_time = 2 + (i * 0.5)  # Pausa progresiva: 2s, 2.5s, 3s...
                    logger.info(f"‚è≥ Pausa de {pause_time}s antes de siguiente b√∫squeda...")
                    time.sleep(pause_time)
                
                # Determinar tipo de b√∫squeda seg√∫n la especialidad
                search_type = self.specialty_config["search_types"][0]
                
                # Realizar b√∫squeda
                results = self.search_system.search(
                    query=query,
                    source_type=search_type,
                    max_results=Config.MAX_RESULTS_PER_QUERY
                )
                
                # Procesar y evaluar cada resultado con pausas entre evaluaciones
                for j, result in enumerate(results):
                    if j > 0:
                        time.sleep(1)  # 1 segundo entre evaluaciones LLM
                    
                    fragment = self._evaluate_result(result, query)
                    if fragment and fragment.final_score >= Config.MIN_FRAGMENT_SCORE:
                        all_fragments.append(fragment)
                
                # Guardar historial de b√∫squeda
                self.search_history.append({
                    "query": query,
                    "results_count": len(results),
                    "timestamp": datetime.now()
                })
                
            except SearchError as e:
                logger.warning(f"‚ö†Ô∏è Error en b√∫squeda '{query}': {e}")
                continue
            except Exception as e:
                logger.error(f"‚ùå Error inesperado en b√∫squeda '{query}': {e}")
                continue
        
        # Procesar los fragmentos: eliminar duplicados y ordenar por score
        unique_fragments = self._remove_duplicates(all_fragments)
        best_fragments = sorted(unique_fragments, key=lambda f: f.final_score, reverse=True)
        
        logger.info(f"‚úÖ {self.agent_id} encontr√≥ {len(best_fragments)} fragmentos v√°lidos")
        return best_fragments[:Config.MAX_FRAGMENTS_PER_AGENT]
    
    def _evaluate_result(self, result: SearchResult, query: str) -> Optional[Fragment]:
        """
        Eval√∫a un resultado de b√∫squeda y lo convierte en fragmento evaluado.
        
        Analiza la calidad del resultado seg√∫n criterios de relevancia,
        credibilidad y sesgo, utilizando el modelo de lenguaje para obtener
        una evaluaci√≥n experta desde la perspectiva del rol especializado.
        
        Args:
            result (SearchResult): Resultado de b√∫squeda a evaluar.
            query (str): Consulta que gener√≥ este resultado.
            
        Returns:
            Optional[Fragment]: Fragmento evaluado si supera los criterios de calidad,
                None en caso contrario.
        """
        try:
            # Validaci√≥n b√°sica del resultado
            if not result.content or len(result.content.strip()) < 50:
                logger.warning(f"‚ö†Ô∏è Resultado muy corto o vac√≠o: {result.title}")
                return None
            
            # Rate limiting para evaluaci√≥n
            self._wait_for_rate_limit()
            
            # Prompt para evaluaci√≥n del fragmento
            evaluation_prompt = f"""
Eres un experto en {self.role.value} evaluando informaci√≥n para el equipo {self.team}.

FRAGMENTO A EVALUAR:
T√≠tulo: {result.title}
Fuente: {result.source}
Contenido: {result.content[:500]}...
URL: {result.url}

Eval√∫a este fragmento en 3 aspectos (responde solo con n√∫meros 0.0-1.0):

1. RELEVANCIA (0.0-1.0): ¬øQu√© tan relevante es para {self.role.value} y √∫til para el equipo {self.team}?
2. CREDIBILIDAD (0.0-1.0): ¬øQu√© tan confiable es la fuente? (acad√©mico=1.0, blog personal=0.3)
3. SESGO (0.0-1.0): ¬øQu√© tan sesgado est√°? (0.0=neutral, 1.0=muy sesgado hacia una posici√≥n)

Despu√©s explica brevemente por qu√© elegiste estos scores.

Formato:
RELEVANCIA: 0.X
CREDIBILIDAD: 0.X
SESGO: 0.X
RAZONAMIENTO: explicaci√≥n breve
"""
            
            response = self.llm.invoke(evaluation_prompt)
            scores = self._parse_evaluation(response.content)
            
            if not scores:
                logger.warning(f"‚ö†Ô∏è No se pudieron parsear scores para: {result.title}")
                return None
            
            # Calcular score final
            final_score = self._calculate_final_score(
                scores["relevancia"],
                scores["credibilidad"], 
                scores["sesgo"]
            )
            
            # Validaci√≥n de score m√≠nimo
            if final_score < Config.MIN_FRAGMENT_SCORE:
                logger.debug(f"üìâ Fragment descartado por score bajo: {final_score:.2f}")
                return None
            
            # Crear fragmento evaluado
            return Fragment(
                content=result.content,
                title=result.title,
                url=result.url,
                source=result.source,
                relevance_score=scores["relevancia"],
                credibility_score=scores["credibilidad"],
                bias_score=scores["sesgo"],
                final_score=final_score,
                agent_reasoning=scores.get("razonamiento", ""),
                search_query=query,
                timestamp=datetime.now(),
                supervisor_team="",  # Se asigna despu√©s por el supervisor
                supervisor_position=""  # Se asigna despu√©s por el supervisor
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error evaluando fragmento: {e}")
            return None
    
    def _parse_evaluation(self, evaluation_text: str) -> Optional[Dict[str, Any]]:
        """
        Parsea la respuesta de evaluaci√≥n del modelo de lenguaje.
        
        Extrae las puntuaciones y el razonamiento del texto de evaluaci√≥n
        generado por el modelo, validando que los valores est√©n dentro del
        rango esperado.
        
        Args:
            evaluation_text (str): Texto de evaluaci√≥n del modelo.
            
        Returns:
            Optional[Dict[str, Any]]: Diccionario con puntuaciones y razonamiento,
                o None si no se pueden extraer los datos necesarios.
        """
        try:
            scores = {}
            lines = evaluation_text.strip().split('\n')
            
            # Extraer puntuaciones y razonamiento del texto
            for line in lines:
                line = line.strip()
                if 'RELEVANCIA:' in line:
                    value = line.split(':')[1].strip()
                    scores["relevancia"] = float(value)
                elif 'CREDIBILIDAD:' in line:
                    value = line.split(':')[1].strip()
                    scores["credibilidad"] = float(value)
                elif 'SESGO:' in line:
                    value = line.split(':')[1].strip()
                    scores["sesgo"] = float(value)
                elif 'RAZONAMIENTO:' in line:
                    scores["razonamiento"] = line.split(':', 1)[1].strip()
            
            # Validar que est√©n todas las puntuaciones requeridas
            required_keys = ["relevancia", "credibilidad", "sesgo"]
            if all(key in scores for key in required_keys):
                # Validar que las puntuaciones est√©n en el rango correcto
                for key in required_keys:
                    if not (0.0 <= scores[key] <= 1.0):
                        logger.warning(f"‚ö†Ô∏è Score fuera de rango para {key}: {scores[key]}")
                        return None
                return scores
            
            logger.warning(f"‚ö†Ô∏è Faltan scores requeridos. Encontrados: {list(scores.keys())}")
            return None
            
        except (ValueError, IndexError) as e:
            logger.warning(f"‚ö†Ô∏è Error parseando evaluaci√≥n: {e}")
            return None
    
    def _calculate_final_score(self, relevance: float, credibility: float, bias: float) -> float:
        """
        Calcula la puntuaci√≥n final combinada del fragmento.
        
        Aplica una f√≥rmula ponderada que combina relevancia, credibilidad y sesgo,
        donde relevancia y credibilidad tienen mayor peso, y el sesgo se invierte
        (menor sesgo = mejor puntuaci√≥n).
        
        Formula: (relevancia * 0.4) + (credibilidad * 0.4) + ((1-sesgo) * 0.2)
        
        Args:
            relevance (float): Puntuaci√≥n de relevancia (0-1).
            credibility (float): Puntuaci√≥n de credibilidad (0-1).
            bias (float): Puntuaci√≥n de sesgo (0-1, donde 0=neutral).
            
        Returns:
            float: Puntuaci√≥n final entre 0.0 y 1.0.
        """
        final = (relevance * 0.4) + (credibility * 0.4) + ((1 - bias) * 0.2)
        return min(max(final, 0.0), 1.0)  # Asegurar que est√© entre 0-1
    
    def _remove_duplicates(self, fragments: List[Fragment]) -> List[Fragment]:
        """
        Elimina fragmentos duplicados o muy similares de la lista.
        
        Identifica duplicados tanto por URL como por similitud de contenido,
        manteniendo siempre el fragmento de mayor puntuaci√≥n cuando hay duplicados.
        
        Args:
            fragments (List[Fragment]): Lista de fragmentos a procesar.
            
        Returns:
            List[Fragment]: Lista de fragmentos sin duplicados.
        """
        unique_fragments = []
        seen_urls = set()
        
        for fragment in fragments:
            # Omitir si ya vimos esta URL
            if fragment.url in seen_urls:
                continue
            
            # Verificar similitud de contenido con fragmentos existentes
            is_duplicate = False
            for existing in unique_fragments:
                if self._content_similarity(fragment.content, existing.content) > Config.SIMILARITY_THRESHOLD:
                    # Mantener el fragmento de mayor puntuaci√≥n
                    if fragment.final_score > existing.final_score:
                        unique_fragments.remove(existing)
                        break
                    else:
                        is_duplicate = True
                        break
            
            # Agregar el fragmento si no es duplicado o si es mejor que el existente
            if not is_duplicate:
                unique_fragments.append(fragment)
                seen_urls.add(fragment.url)
        
        return unique_fragments
    
    def _content_similarity(self, content1: str, content2: str) -> float:
        """
        Calcula el √≠ndice de similitud entre dos textos.
        
        Utiliza el coeficiente de Jaccard (intersecci√≥n/uni√≥n de conjuntos de palabras)
        para determinar la similitud entre los contenidos.
        
        Args:
            content1 (str): Primer texto a comparar.
            content2 (str): Segundo texto a comparar.
            
        Returns:
            float: √çndice de similitud entre 0.0 (totalmente diferentes) y 
                1.0 (id√©nticos en t√©rminos de palabras).
        """
        words1 = set(content1.lower().split())
        words2 = set(content2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0
    
    def research(self, task: str, context: str = "") -> List[Fragment]:
        """
        M√©todo principal que realiza el proceso completo de investigaci√≥n.
        
        Ejecuta la secuencia completa de investigaci√≥n: generaci√≥n de consultas,
        b√∫squeda de informaci√≥n, evaluaci√≥n de resultados y selecci√≥n de los
        mejores fragmentos, con manejo de errores robusto.
        
        Args:
            task (str): Tarea principal de investigaci√≥n.
            context (str, optional): Contexto adicional del debate.
            
        Returns:
            List[Fragment]: Lista de los mejores fragmentos encontrados y evaluados.
        """
        logger.info(f"üöÄ {self.agent_id} iniciando investigaci√≥n: {task}")
        
        try:
            # Validaci√≥n de entrada
            if not task or len(task.strip()) < 10:
                logger.warning(f"‚ö†Ô∏è Tarea muy corta para {self.agent_id}: '{task}'")
                return []
            
            # 1. Generar queries especializadas
            queries = self.generate_search_queries(task, context)
            
            if not queries:
                logger.warning(f"‚ö†Ô∏è No se generaron queries para {self.agent_id}")
                return []
            
            # 2. Buscar y evaluar resultados
            fragments = self.search_and_evaluate(queries)
            
            # 3. Guardar resultados en el estado interno
            self.fragments_found = fragments
            
            logger.info(f"‚úÖ {self.agent_id} complet√≥ investigaci√≥n: {len(fragments)} fragmentos")
            return fragments
            
        except Exception as e:
            logger.error(f"‚ùå Error en investigaci√≥n de {self.agent_id}: {e}")
            return []
    
    def get_status(self) -> Dict[str, Any]:
        """
        Devuelve el estado actual detallado del agente.
        
        Proporciona informaci√≥n completa sobre el agente, sus actividades,
        estad√≠sticas y resultados para monitoreo y depuraci√≥n.
        
        Returns:
            Dict[str, Any]: Diccionario con el estado completo del agente.
        """
        return {
            "agent_id": self.agent_id,
            "role": self.role.value,
            "team": self.team,
            "queries_used": len(self.queries_used),
            "fragments_found": len(self.fragments_found),
            "searches_performed": len(self.search_history),
            "api_calls_made": self.api_calls_count,
            "avg_fragment_score": sum(f.final_score for f in self.fragments_found) / len(self.fragments_found) if self.fragments_found else 0,
            "specialty_keywords": self.specialty_config["keywords"],
            "last_search_time": self.search_history[-1]["timestamp"].isoformat() if self.search_history else None
        }